{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM4noyvcpZ1P3NcBG7+nYzs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ggMlT6-ea-Vb"},"outputs":[],"source":["pip install boto3"]},{"cell_type":"code","source":["pip install atproto"],"metadata":{"id":"7hzDfXRLcDK5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# aws stuff\n","import boto3\n","from botocore.exceptions import ClientError\n","# json necessary to parse secret string, and write/read s3 objects\n","import json\n","\n","# From the transformers package, import ViTImageProcessor and ViTForImageClassification\n","from transformers import ViTImageProcessor, ViTForImageClassification\n","\n","# From the PIL package, import Image and Markdown\n","from PIL import Image\n","\n","# import requests\n","import requests\n","\n","# import torch\n","import torch\n","\n","# import matplotlib\n","import matplotlib.pyplot as plt\n","\n","# url getter for mpl\n","import urllib\n","\n","import numpy as np\n","\n","# import bluesky api\n","from atproto import Client\n","\n","# import colab secrets to store login credentials\n","from google.colab import userdata\n","\n","# datetime is necessary for caturday check and logging\n","import datetime\n","import zoneinfo\n","\n","# these imports are to use github apis to do logging, base64 is to parse the json\n","# import requests # already imported for something else\n","import base64\n","\n","# adding a hugginface login so that we can authenticate\n","from huggingface_hub import login"],"metadata":{"id":"BDvr6S3GcQct"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# input variables - x is target follows y is num of posts we want to look through, whichever end criteria we reach first\n","EMBEDDED_PIC = 'app.bsky.embed.images#view'\n","EMBEDDED_VID = 'app.bsky.embed.video#view'\n","FEED_CATURDAY = 'at://did:plc:tenurhgjptubkk5zf5qhi3og/app.bsky.feed.generator/#caturday'\n","FEED_SIAMESE = 'at://did:plc:jv3qdc5vxujp6taaa7nte35i/app.bsky.feed.generator/aaac6wmikqyhq'\n","# FEED_CATPICS = 'at://did:plc:q6gjnaw2blty4crticxkmujt/app.bsky.feed.generator/cv:cat'\n","# FEED_CATS = 'at://did:plc:jfhpnnst6flqway4eaeqzj2a/app.bsky.feed.generator/cats'\n","# FEED_TUXEDOCATS = 'at://did:plc:eubjsqnf5edgvcc6zuoyixhw/app.bsky.feed.generator/tuxedo-cats'\n","# FEED_CATURDAY = 'at://did:plc:pmyqirafcp3jqdhrl7crpq7t/app.bsky.feed.generator/aaad4sb7tyvjw' # this one is old idk why it disappeared but it was still working?\n","FEED_NAME = {FEED_CATURDAY: \"'Caturday'\", FEED_SIAMESE: \"'Siamese Cats'\", FEED_CATPICS: \"'Cat Pics'\", FEED_CATS: \"'Cats!'\", FEED_TUXEDOCATS: \"'Tuxedo Cats'\"}\n","URL_BEGIN = 'https://bsky.app/profile/'\n","URL_POST = '/post/'\n","# my did to check against\n","MY_DID = 'did:plc:ktkc7jfakxzjpooj52ffc6ra'\n","\n","# query creation constants\n","SCHEMA = '\"bsky\"'\n","TABLE_FOLLOWS = '\"follows\"'\n","COL_USERID = 'user_id'\n","COL_USERHANDLE = 'user_handle'\n","COL_FOLLOWURI = 'follow_uri'\n","COL_FOLLOWDATE = 'follow_date'\n","COL_FOLLOWSYOU = 'follows_you'\n","DATETIME_NOW = 'NOW()'\n","END_LINE = ','\n","END_QUERY = ';'\n","TABLE_POSTS = '\"posts\"'\n","COL_POSTCID = 'post_cid'\n","COL_SEENTIME = 'seen_time'\n","\n","CATURDAY_DOW = 'Saturday'\n","USER_TIMEZONE = \"US/Eastern\" # you should fill this in with your own timezone here\n","\n","LINE_BREAK = '\\n'\n","END_LOGGING = '\\n____________________\\n'\n","\n","FILE_PATH = \"LOGGING_ADD_02.txt\"  # Replace with the file path in your repo\n","BRANCH = \"main\"  # Replace with your branch name\n","\n","AWS_KEY = userdata.get('aws_access_key')\n","AWS_SECRET_KEY = userdata.get('aws_secret_access_key')\n","REGION = userdata.get('aws_region')\n","SECRETS_ID = userdata.get('aws_secretsmanager_id')\n","\n","DDB = 'dynamodb'\n","S3 = 's3'\n","DDB_TABLE = 'rickybot-ddb'\n","S3_BUCKET = 'rickybot-s3'\n","DDB_CACHE_KEY = 'CACHE'\n","DDB_CACHE_ATTRIBUTE = 'CIDS'\n","\n","PRIMARY_KEY = 'DOW' # the dynamodb table's primary key. there is no sort key\n","DOW_KEYS = {\n","    'Sunday': 'SUN',\n","    'Monday': 'MON',\n","    'Tuesday': 'TUE',\n","    'Wednesday': 'WED',\n","    'Thursday': 'THU',\n","    'Friday': 'FRI+SAT',\n","    'Saturday': 'FRI+SAT'\n","}\n","\n","# run settings\n","POSTS_CATURDAY = 1000\n","FOLLOWS_CATURDAY = 1000 #350 when automated to 1 run per 1 hour\n","POSTS_OTHERCAT = 1000\n","FOLLOWS_OTHERCAT = 1000 # 400 when automated to 1 run per 2 hours\n","# running these very frequently so we don't need to do too many:\n","# by my math cap for day is 9250, so 1 run per hr caps at 385, 2 hours is 770, but we need to save some of that room for deletions, especially on Fridays. So when we automate I want to do 1000-350, 1000-400"],"metadata":{"id":"jZOL86rtcwZB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get the day of the week so we know what dynamodb key to pull from and which bucket to aggregate to\n","# doing this first because we do not run this on saturday and can bail out early if we get into this code for some reason\n","# also we are running this at about 1am, the following day after all runs have concluded for the previous. so we're aggregating the previous day's results\n","cur_timestamp = datetime.datetime.now(zoneinfo.ZoneInfo(USER_TIMEZONE))\n","dow = cur_timestamp.strftime(\"%A\")\n","str_timestamp = str(cur_timestamp) # we'll need this to use as the attribute for ddb\n","\n","# use the day of the week to pull up the corresponding key for our dynamodb entries and our s3 bucket\n","ddb_key = DOW_KEYS[dow]\n","print(ddb_key)\n","\n","# also this is where we can initialize our RUNNING LOG string.\n","running_logging_text = str_timestamp + LINE_BREAK"],"metadata":{"id":"iKU2GNb1ka8I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# connect to aws\n","try:\n","  aws_session = boto3.Session(\n","          aws_access_key_id = AWS_KEY,\n","          aws_secret_access_key = AWS_SECRET_KEY,\n","          region_name = REGION\n","      )\n","except:\n","  print('failed to begin AWS session')\n","  # return with error\n","  # this is the only error that we can't log to github, because we never got the credentials"],"metadata":{"id":"2FTtO8_NlEjm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# then connect to secrets manager\n","try:\n","  secrets_client = aws_session.client('secretsmanager')\n","  secret_value = secrets_client.get_secret_value(SecretId=SECRETS_ID)\n","  secret_string = secret_value['SecretString']\n","  secret_map = json.loads(secret_string)\n","except:\n","  print('failed to reach aws secrets manager')\n","  # return with error"],"metadata":{"id":"l9-Q-bsblKyE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create constants from the values in the secrets manager\n","BSKY_USERNAME = secret_map['bsky_username']\n","BSKY_PASS = secret_map['bsky_password']\n","GITHUB_TOKEN = secret_map['github_token']\n","GITHUB_REPO = secret_map['github_user/repo']\n","HUGGING_TOKEN = secret_map['hugging_token']"],"metadata":{"id":"Vx9IOCxJlPsN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# now that we have our github token set up we should set up our logging function to use whenever we encounter any errors\n","def logging_add(logging_text)\n","  # LOGGING ALL THE CHANGES TO OUR LOGGING FILE IN GITHUB\n","  commit_message = \"Logging for follower additions on \" + str_timestamp\n","\n","  # Step 1: Get the file's current content and SHA\n","  url = f\"https://api.github.com/repos/{GITHUB_REPO}/contents/{FILE_PATH}\"\n","  headers = {\"Authorization\": f\"token {GITHUB_TOKEN}\"}\n","  response = requests.get(url, headers=headers)\n","  response_json = response.json()\n","\n","  # Decode the content of the file\n","  file_sha = response_json[\"sha\"]\n","  content = base64.b64decode(response_json[\"content\"]).decode(\"utf-8\")\n","\n","  # Step 2: Modify the file content\n","  new_content = content + LINE_BREAK + logging_text + END_LOGGING\n","  encoded_content = base64.b64encode(new_content.encode(\"utf-8\")).decode(\"utf-8\")\n","\n","  # Step 3: Push the updated content\n","  data = {\n","      \"message\": commit_message,\n","      \"content\": encoded_content,\n","      \"sha\": file_sha,\n","      \"branch\": BRANCH,\n","  }\n","  update_response = requests.put(url, headers=headers, json=data)\n","\n","  if update_response.status_code == 200:\n","      print(\"Logging file updated successfully! Here's what was added to the logs:\\n\")\n","      print(logging_text + END_LOGGING)\n","  else:\n","      print(f\"Error: {update_response.json()}\")"],"metadata":{"id":"GtRYmNMdqhny"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# log in to huggingface to authenticate\n","try:\n","  login(HUGGINGFACE_TOKEN)\n","except:\n","  warning = 'WARNING - failed to authenticate huggingface'\n","  print(warning)\n","  running_logging_text += warning + LINE_BREAK\n","  # this should NOT return early due to this error, as the huggingface authentication is not necessary to use the public model we're using"],"metadata":{"id":"dTy3VZegpTh1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# initialize the ViT model\n","try:\n","  # Load the feature extractor for the vision transformer\n","  feature_extractor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\n","  # Load the pre-trained weights from vision transformer\n","  model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n","except:\n","  print('ERROR - failed to initialize ViT model')\n","  running_logging_text += 'ERROR - failed to initialize ViT model'\n","  logging_add(running_logging_text)\n","  # this is a critical failure, so return early here"],"metadata":{"id":"U0l-ClcJtpPQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# next we need to retrieve our cached posts from the dynamodb, so log into dynamodb here\n","try:\n","  dynamodb = aws_session.resource(DDB)\n","  table = dynamodb.Table(DDB_TABLE)\n","except:\n","  err = 'ERROR - failed to get dynamo db table'\n","  print(err)\n","  running_logging_text += err\n","  logging_add(running_logging_text)\n","  # return with error, we cant add the results to the db and we can't retrieve the cache (which isn't as important, but still)"],"metadata":{"id":"vzfIbEqTuejS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# pull the cache of post CIDs seen in the previous run from dynamodb - if we fail any step here just leave a warning that we couldn't check the cache\n","cached_posts = set() # in case the ddb fails to retrieve, initialize an empty set\n","ddb_response = {} # same reason\n","seen_posts = set() # initialize the seen posts set, we'll be using it to replace our cache at the end of the run\n","try:\n","  ddb_response = table.get_item(\n","      Key={'DOW': DDB_CACHE_KEY},\n","  )\n","except ClientError as e:\n","  warning = f\"WARNING - failed to check post cache key's existence: {e}\"\n","  print(warning)\n","  running_logging_text += warning + LINE_BREAK\n","\n","# print('ddb response:', ddb_response)\n","# this if else checks to see if there is anything\n","if 'Item' not in ddb_response:\n","  # check the status code to skip a redundant warning, if we errored out before there will be no key\n","  if 'HTTPStatusCode' in ddb_response and ddb_response['HTTPStatusCode'] == 200:\n","    warning = 'WARNING - successful response from dynamodb but there were no items in the post cache key.'\n","    print(warning)\n","    running_logging_text += warning + LINE_BREAK\n","else:\n","  if DDB_CACHE_ATTRIBUTE in ddb_response['Item']:\n","    cached_posts = ddb_response['Item'][DDB_CACHE_ATTRIBUTE]\n","    print(f'imported {len(cached_posts)} prior seen posts from the dynamodb table')\n","  else:\n","    warning = 'WARNING - somehow there were items in the dynamodb cache key, but the attribute for cached posts was not present'\n","    print(warning)\n","    running_logging_text += warning + LINE_BREAK"],"metadata":{"id":"FQZ2F_KPwomo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# and now we can log into the bluesky client\n","try:\n","  client = Client()\n","  client.login(BSKY_USERNAME, BSKY_PASSWORD)\n","except:\n","  err = 'ERROR - failed to log in to the bluesky client'\n","  print(err)\n","  running_logging_text += err\n","  logging_add(running_logging_text)\n","  # return here, cannot proceed without bluesky"],"metadata":{"id":"zXpDAZHX-CnL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# this is our code to identify post images as catposts\n","\n","# 281: 'tabby, tabby cat'\n","# 282: 'tiger cat', 283: 'Persian cat', 284: 'Siamese cat, Siamese', 285: 'Egyptian cat', 286: 'cougar, puma, catamount, mountain lion, painter, panther, Felis concolor', 287: 'lynx, catamount', 288: 'leopard, Panthera pardus', 289: 'snow leopard, ounce, Panthera uncia', 290: 'jaguar, panther, Panthera onca, Felis onca', 291: 'lion, king of beasts, Panthera leo', 292: 'tiger, Panthera tigris', 293: 'cheetah, chetah, Acinonyx jubatus',\n","# 281 to 293\n","cat_labels = set()\n","for i in range(281, 294):\n","  cat_labels.add(i)\n","\n","# these labels are to remove drawings, memes/reposts, and images with a lot of text respectively\n","bad_labels = {\n","917 : 'comic book', 916 : 'web site, website, internet site, site', 921 : 'book jacket, dust cover, dust jacket, dust wrapper'}\n","\n","def test_bsky_image(url):\n","  f = urllib.request.urlopen(url)\n","  image = plt.imread(f, format='jpeg')\n","  # plt.imshow(image)\n","  inputs = feature_extractor(images=image, return_tensor=\"pt\")\n","  pixel_values = inputs[\"pixel_values\"]\n","  pixel_values = np.array(pixel_values)\n","  pixel_values = torch.tensor(pixel_values)\n","  outputs = model(pixel_values)\n","  logits = outputs.logits\n","  predicted_class_idx = logits.argmax(-1).item()\n","  sorted_preds = torch.argsort(logits, descending=True)[0]\n","  top_predictions = [sorted_preds[i].item() for i in range(50)] # 50 is semi-arbitrary based on our findings from testing pics # could see tuning this down to 40 but can't tell if it would pick up more or less cats\n","  top_values = [logits[0][pred].item() for pred in top_predictions]\n","  # print('label predictions', top_predictions)\n","  # print('values of predictions', top_values)\n","  found_cat_label = -1\n","  found_bad_label = -1\n","  bad_labels_found = []\n","  cat_score = 0\n","  for i, pred in enumerate(top_predictions):\n","    predicted_class = model.config.id2label[pred]\n","    # print(predicted_class)\n","    if pred in cat_labels:\n","      if found_cat_label == -1:\n","        found_cat_label = i\n","      cat_score += top_values[i]\n","    if pred in bad_labels:\n","      if found_bad_label == -1:\n","        found_bad_label = i\n","      bad_labels_found.append(pred)\n","      bad_labels_found.append(bad_labels[pred])\n","      cat_score -= top_values[i]\n","  # print(' ')\n","  print('    found cat label:', found_cat_label)\n","  print('    found bad label:', found_bad_label, bad_labels_found)\n","  would_pass = found_cat_label >= 0 and found_bad_label < 0\n","  # print('AI cat score: ', cat_score)\n","  # print('    passed cat test:', would_pass)\n","  return would_pass"],"metadata":{"id":"9b45qbkp9PWd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# just getting a previous count of our followers and following for the logs\n","try:\n","  following = client.get_profile(actor=BSKY_USERNAME).follows_count\n","  followers = client.get_profile(actor=BSKY_USERNAME).followers_count\n","  prev_stats = f'prior followers: {str(followers)} | previously following: {str(following)}'\n","  print(prev_stats)\n","  running_logging_text += prev_stats + LINE_BREAK\n","except:\n","  warning = 'WARNING - failed to get previous following and followers count'\n","  print(warning)\n","  running_logging_text += warning + LINE_BREAK"],"metadata":{"id":"n1Q7n-LC-eRf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# after successfully identifying a cat post, this function likes the post and follows the user, returning the follow uri string\n","def like_post_and_add_user(post):\n","  user_did = post.author.did\n","  post_cid = post.cid\n","  post_uri = post.uri\n","  followed_user = ''\n","  try:\n","    followed_user = client.follow(user_did).uri\n","    liked_post = client.like(uri=post_uri, cid=post_cid).uri\n","    print(f'      âœ“âœ“âœ“ âœ… Successfully liked post and followed user: {post.author.handle}')\n","  except:\n","    print(f'      âœ“âœ“âœ— âŒ failed at either liking post or following user: {post.author.handle}')\n","  return followed_user"],"metadata":{"id":"4nwzS4LW_nBw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_post_follow_likers(post_uri, like_count, users_followed, max_new_followers):\n","  # need to try opening post, get the list of likers, iterate through following them, add each to the users added\n","  new_follows_count = 0\n","  likes_remaining = like_count\n","  try:\n","    while likes_remaining > 0:\n","      if (likes_remaining > 100):\n","        print(f'        Starting new page of likes. {likes_remaining} likes remaining to check on this post.')\n","      limit = min(likes_remaining, 100)\n","      likes_remaining -= limit\n","      next_page = ''\n","      response = client.get_likes(uri = post_uri, limit= limit, cursor= next_page)\n","      likes = response.likes\n","      next_page = response.cursor\n","\n","      for like in likes:\n","        you_follow_them = like.actor.viewer.following\n","        you_are_followed_by = like.actor.viewer.followed_by\n","        user_did = like.actor.did\n","        user_handle = like.actor.handle\n","        if you_follow_them or you_are_followed_by or user_did == MY_DID or user_did in users_followed:\n","          print(f'        Already seen user. handle: {user_handle}')\n","          continue\n","        else:\n","          # like the user\n","          follow_uri = client.follow(user_did).uri\n","          date_added = DATETIME_NOW\n","          follows_you = 'FALSE'\n","          users_followed.append(user_did) # now we only need to save the user_did in the set instead of the whole string, and so we don't need a whole second already added dids set\n","          print(f'        Followed post-liker. handle: {user_handle}')\n","          new_follows_count += 1\n","          if new_follows_count >= max_new_followers:\n","            break\n","      # print(f'from {len(likes)} likes on this post you followed {new_followers_count}, saw {follow_them_count} users you already follow, and saw {followed_by_count} users that already follow you')\n","  except Exception as e:\n","    print(f'ERROR: THERE WAS AN ISSUE CHECKING THIS POST FOR LIKES. \\n{e}')\n","  return new_follows_count"],"metadata":{"id":"yg-WCVYYAoA0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def createPostUrl(feed_post):\n","  url_handle = feed_post.post.author.handle\n","  url_ending_index = feed_post.post.uri.find('.feed.post/') + 11\n","  url_ending = feed_post.post.uri[url_ending_index : ]\n","  return URL_BEGIN + url_handle + URL_POST + url_ending\n","\n","def follow_more_users(post_count, follows_count, feed):\n","  if post_count == 0 or follows_count == 0:\n","    return []\n","  posts_to_check = post_count\n","  successful_cat_post_like_count = 3\n","  max_errors_allowed = 5\n","  next_page = ''\n","  new_follow_count_from_posts = 0\n","  new_follow_count_from_likes = 0\n","  page_count = 0\n","  users_followed = set()\n","\n","  logging_posts = 0\n","  logging_pics = 0\n","  logging_errors_count = 0\n","  logging_errors_description = []\n","  logging_notcat = 0\n","  logging_cat = 0\n","  logging_vid = 0\n","  logging_nomedia = 0\n","  logging_alreadyfollowed = 0\n","  logging_mutuals = 0\n","  logging_myposts = 0\n","  logging_seenpost = 0\n","  global running_logging_text\n","  running_logging_text += f'Feed {FEED_NAME[feed]}:' + LINE_BREAK\n","\n","  def log_results():\n","    global running_logging_text\n","    sum_new_follows = new_follow_count_from_posts + new_follow_count_from_likes\n","    sum_skipped_posts = logging_seenpost + logging_alreadyfollowed + logging_myposts\n","    sum_unprocessed = logging_nomedia + logging_vid\n","    print(f'followed {sum_new_follows} new users. {new_follow_count_from_posts} posters and {new_follow_count_from_likes} likers.')\n","    running_logging_text += f'  Followed {sum_new_follows} new user{\"s\" if sum_new_follows != 1 else \"\"}{\"!\" if sum_new_follows > 0 else \".\"}' + LINE_BREAK\n","    running_logging_text += f'    Of those follows, {new_follow_count_from_posts} were posters and {new_follow_count_from_likes} were from likes.' + LINE_BREAK\n","    running_logging_text += f'  {logging_posts} posts in total were viewed during this run.' + LINE_BREAK\n","    running_logging_text += f'  Skipped Posts: ({sum_skipped_posts}) - {logging_seenpost} posts were previously seen, {logging_alreadyfollowed} were from users already followed, {logging_myposts} were your posts.' + LINE_BREAK\n","    running_logging_text += f'  Mutuals: {logging_mutuals} posts were from users that follow you, and these posts were liked.' + LINE_BREAK\n","    running_logging_text += f'  Unprocessed: ({sum_unprocessed}) - {logging_nomedia} posts had no media attached, and {logging_vid} posts had videos attached.' + LINE_BREAK\n","    running_logging_text += f'  Processed: {logging_pics} posts had pics attached: {logging_cat} were identified as cat pics and {logging_notcat} were not cats.' + LINE_BREAK\n","    running_logging_text += f'  {\"No errors were encountered while processing pics.\" if logging_errors_count == 0 else str(logging_errors_count) + \" ERROR(S) ENCOUNTERED PROCESSING PICS FROM THIS FEED\"} ' + LINE_BREAK\n","    if logging_errors_count > 0:\n","      running_logging_text += ';; \\n'.join(logging_errors_description) + LINE_BREAK\n","\n","  while posts_to_check > 0:\n","    print(f'[checking page {page_count} of feed {FEED_NAME[feed]}, {posts_to_check} posts left to check, and have found {new_follow_count_from_posts + new_follow_count_from_likes} new users to follow]')\n","    page_count += 1\n","    limit = min(posts_to_check, 100)\n","    posts_to_check -= limit\n","    try:\n","      # print('next page', next_page)\n","      data = client.app.bsky.feed.get_feed({\n","          'feed': 'at://did:plc:jfhpnnst6flqway4eaeqzj2a/app.bsky.feed.generator/cats',\n","          'limit': limit,\n","          'cursor': next_page\n","      }, headers={})\n","      next_page = data.cursor\n","      # print(data)\n","\n","      for i, f in enumerate(data.feed):\n","        you_follow_them = f.post.author.viewer.following\n","        you_are_followed_by = f.post.author.viewer.followed_by\n","        did = f.post.author.did\n","        post_cid = f.post.cid\n","        seen_posts.add(post_cid) # now that we're using a dynamodb cache we want to add the cid to the seen posts set regardless of what happens to it so that it's saved for next run\n","\n","        logging_posts += 1\n","        if did == MY_DID:\n","          print(f'{i} - ðŸ˜Ž skipped. This was your own post.')\n","          logging_myposts += 1\n","          continue\n","        elif post_cid in cached_posts or post_cid in seen_posts:\n","          print(f'{i} - ðŸ‘€ skipped. Post with cid {post_cid} has already been viewed. Found in {\"db cache\" if post_cid in cached_posts else \"current set\"}.')\n","          logging_seenpost += 1\n","          continue\n","        else:\n","          # TODO: the way I have it if you are following them you never check the photo to see if it's a good one to get the likes from.\n","          if you_follow_them and you_are_followed_by:\n","            print(f'{i} ðŸ’• user: {f.post.author.handle} is a mutual follower. Liking this post. {createPostUrl(f)}')\n","            # this can break if you get rate limited. So far hasn't broken when posts are deleted but should have been wrapped in one just in case\n","            try:\n","              liked_post = client.like(uri=f.post.uri, cid=f.post.cid).uri\n","            except Exception as e:\n","              logging_errors_count += 1\n","              print(f'    âœ“âœ— â€¼ï¸ liking post {i} caused an error. {logging_errors_count} errors seen this run.\\n{e}')\n","              logging_errors_description.append(f'{i}. {e}')\n","              # got rate limited and know that if you hit like 100 errors or so you'll eventually get a timeout and the entire nootebook will be borked.\n","              if logging_errors_count >= max_errors_allowed:\n","                print(f'seen more errors ({logging_errors_count}) than the acceptable number of errors ({max_errors_allowed}). terminating run.')\n","                log_results()\n","                return users_followed\n","            logging_mutuals += 1\n","          elif did in already_added_dids:\n","            print(f'{i} âœ— ðŸ‘€ user: {f.post.author.handle} was already followed in this batch.')\n","            logging_alreadyfollowed += 1\n","          elif you_follow_them or you_are_followed_by:\n","            print(f'{i} âœ— ðŸ‘€ user: {f.post.author.handle} {\"already follows you.\" if you_are_followed_by else \"\"}{\"is already being followed.\" if you_follow_them else \"\"}')\n","            logging_alreadyfollowed += 1\n","          elif not f.post.embed or f.post.embed.py_type != EMBEDDED_PIC:\n","            if f.post.embed.py_type == EMBEDDED_VID:\n","              print(f'{i} âœ— ðŸŽ¥ video post: {createPostUrl(f)}')\n","              logging_vid += 1\n","            else:\n","              print(f'{i} âœ— ðŸ”² no pic for post {i}')\n","              logging_nomedia += 1\n","          else:\n","            print(i, 'âœ“', 'ðŸ“·', f.post.embed.images[0].fullsize)\n","            print(f'    post: {createPostUrl(f)}')\n","            logging_pics += 1\n","            try:\n","              handle = f.post.author.handle\n","              print(f'    user: {handle}')\n","              is_cat = test_bsky_image(f.post.embed.images[0].fullsize)\n","              if is_cat:\n","                print(f'    âœ“âœ“ ðŸ˜º successfully found cat pic at post {i}. It has {f.post.like_count} likes.')\n","                new_follow_count_from_posts += 1\n","                logging_cat += 1\n","                follow_uri = like_post_and_add_user(f.post)\n","                date_added = DATETIME_NOW\n","                follows_you = 'FALSE'\n","                users_followed.add(did)\n","                # so we have a cat post. If it is a solid or particularly good cat post it should probably have a lot of likes, and we can go in and follow all those likers\n","                if f.post.like_count >= successful_cat_post_like_count:\n","                  print(f'      ðŸ‘ðŸ» This cat post got {f.post.like_count}, and I would call it successful, so following its likers.')\n","                  likers_added = get_post_follow_likers(f.post.uri, f.post.like_count, users_followed, follows_count - (new_follow_count_from_posts + new_follow_count_from_likes))\n","                  print(f'      {\"âœ…\" if likers_added > 0 else \"0ï¸âƒ£\"} Added {likers_added} users that liked that post.')\n","                  new_follow_count_from_likes += likers_added\n","                if new_follow_count_from_posts + new_follow_count_from_likes >= follows_count:\n","                  print(f'Successfully followed the desired number of new users! breaking out of loop.')\n","                  break\n","              else:\n","                print(f'    âœ“âœ— âŒ post {i} was not a cat pic')\n","                logging_notcat += 1\n","            except Exception as e:\n","              logging_errors_count += 1\n","              print(f'    âœ“âœ— â“ post {i} image caused an error. {logging_errors_count} errors seen this run.\\n{e}')\n","              print(f'errors ({logging_errors_count}), acceptable number of errors ({max_errors_allowed}).')\n","              logging_errors_description.append(f'{i}. {e}')\n","              # got rate limited and know that if you hit like 100 errors or so you'll eventually get a timeout and the entire notebook will be borked.\n","              if logging_errors_count >= max_errors_allowed:\n","                print(f'seen more errors ({logging_errors_count}) than the acceptable number of errors ({max_errors_allowed}). terminating run.')\n","                log_results()\n","                return users_followed\n","    except Exception as e:\n","      print(f'error encountered from trying to get feed. terminating run.\\n{repr(e)}: {e}')\n","      logging_errors_count += 1\n","      logging_errors_description.append('CRITICAL ERROR ENCOUNTERED WHILE GETTING FEED:')\n","      logging_errors_description.append(f'{repr(e)}: {e}')\n","      log_results()\n","      return users_followed\n","  log_results()\n","  return users_followed\n","\n","    # print(data.feed[0].post.embed.images[0].fullsize)"],"metadata":{"id":"NwdXsZxkBE5i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# FINALLY THE ACTUAL RUN! determine whether you're checking the caturday feed or the regular cat feed\n","is_caturday = dow == CATURDAY_DOW\n","followed_users = set()\n","if is_caturday:\n","  print(\"IT'S CATURDAY! Checking the Caturday feed for new followers.\")\n","  followed_users = follow_more_users(POSTS_CATURDAY, FOLLOWS_CATURDAY, FEED_CATURDAY)\n","else:\n","  print(\"Just a regular day, but we're still following more cats. :3\")\n","  followed_users = follow_more_users(POSTS_OTHERCAT, FOLLOWS_OTHERCAT, FEED_SIAMESE)\n","\n","# just in case we said we followed ourselves somehow, we'll discard that value\n","followed_users.discard(MY_DID)\n","# and add the results to our dynamodb\n","if len(followed_users) > 0:\n","  try:\n","    table.update_item(\n","        Key={'DOW': ddb_key},\n","        UpdateExpression='SET #attr = :val',\n","        ExpressionAttributeNames={\n","            '#attr': str_timestamp\n","        },\n","        ExpressionAttributeValues={\n","            ':val': followed_users\n","        }\n","    )\n","  except ClientError as e:\n","    err = f'ERROR - failed to store followed users in dynamodb.\\n{e}'\n","    print(err)\n","    running_logging_text += err"],"metadata":{"id":"mv3fso1Rd_IK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# now we also need to update the cached posts with what we saw this run\n","try:\n","  table.update_item(\n","      Key={'DOW': DDB_CACHE_KEY},\n","      UpdateExpression='SET #attr = :val',\n","      ExpressionAttributeNames={\n","          '#attr': DDB_CACHE_ATTRIBUTE\n","      },\n","      ExpressionAttributeValues={\n","          ':val': seen_posts\n","      }\n","  )\n","except ClientError as e:\n","  warning = f'WARNING - failed to store followed users in dynamodb.\\n{e}'\n","  print(warning)\n","  running_logging_text += warning + LINE_BREAK"],"metadata":{"id":"05NuSjQOkTmx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["end_timestamp = datetime.datetime.now(zoneinfo.ZoneInfo(USER_TIMEZONE))\n","time_diff = end_timestamp - cur_timestamp\n","running_logging_text += f'time diff: {str(time_diff)} | completed run at: {str(end_timestamp)}' + LINE_BREAK\n","print(f'end timestamp: {end_timestamp}\\ntime diff (runtime): {time_diff}')"],"metadata":{"id":"ta6C-MeXkXII"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# now get an updated count of our followers and following for the logs\n","try:\n","  following = client.get_profile(actor=BSKY_USERNAME).follows_count\n","  followers = client.get_profile(actor=BSKY_USERNAME).followers_count\n","  cur_stats = f'cur followers: {str(followers)} | now following: {str(following)}'\n","  print(cur_stats)\n","  running_logging_text += cur_stats + LINE_BREAK\n","except:\n","  warning = 'WARNING - failed to get updated following and followers count'\n","  print(warning)\n","  running_logging_text += warning + LINE_BREAK"],"metadata":{"id":"ZLp7Fl0DkbfT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# a successful run! add our logging string\n","logging_add(running_logging_text)"],"metadata":{"id":"HGmihePqkgOZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# and for debugging purposes, I want to scan the dynamodb table to see how it's looking now.\n","# THIS SHOULD NOT BE IN THE FINAL CODE\n","print(table.scan())"],"metadata":{"id":"MmKzgdhcmTnS"},"execution_count":null,"outputs":[]}]}